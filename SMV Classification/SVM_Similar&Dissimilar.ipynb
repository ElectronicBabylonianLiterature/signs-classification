{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Dissimilar Signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "   U₂ Neo-Assyrian       0.29      0.48      0.36        23\n",
      " NI Neo-Babylonian       0.33      0.35      0.34        43\n",
      "   TA Neo-Assyrian       0.33      0.53      0.41        19\n",
      " ŠU Neo-Babylonian       0.28      0.32      0.30        28\n",
      " U₂ Neo-Babylonian       0.26      0.37      0.31        41\n",
      "  GAR Neo-Assyrian       0.40      0.54      0.46        39\n",
      " RU Neo-Babylonian       0.17      0.18      0.18        22\n",
      " TI Neo-Babylonian       0.50      0.57      0.53        35\n",
      "  E Neo-Babylonian       0.08      0.08      0.08        13\n",
      "   KA Neo-Assyrian       0.16      0.25      0.20        16\n",
      " KA Neo-Babylonian       0.56      0.41      0.47        49\n",
      "   ŠU Neo-Assyrian       0.62      0.40      0.49        25\n",
      "  MEŠ Neo-Assyrian       0.42      0.27      0.33        30\n",
      "GAR Neo-Babylonian       0.63      0.62      0.62        63\n",
      "   KI Neo-Assyrian       0.45      0.30      0.36        43\n",
      "MEŠ Neo-Babylonian       0.22      0.24      0.23        25\n",
      "   TI Neo-Assyrian       0.29      0.33      0.31        24\n",
      " TA Neo-Babylonian       0.17      0.13      0.15        23\n",
      "   RU Neo-Assyrian       0.25      0.19      0.22        26\n",
      " KI Neo-Babylonian       0.33      0.25      0.29        44\n",
      "   NI Neo-Assyrian       0.23      0.24      0.24        33\n",
      "    E Neo-Assyrian       0.40      0.17      0.24        24\n",
      "\n",
      "          accuracy                           0.36       688\n",
      "         macro avg       0.34      0.33      0.32       688\n",
      "      weighted avg       0.37      0.36      0.36       688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading of the images and assigning a label to each image\n",
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = plt.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Resize the images and flatten\n",
    "def preprocess(images):\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        resized_img = cv2.resize(img, (128, 128))  \n",
    "        flattened_img = resized_img.flatten()\n",
    "        processed_images.append(flattened_img)\n",
    "    return processed_images\n",
    "\n",
    "root_folder = 'dissimilar signs'\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "for class_name in os.listdir(root_folder):\n",
    "    class_folder = os.path.join(root_folder, class_name)\n",
    "    if os.path.isdir(class_folder):\n",
    "        images, labels = load_images_from_folder(class_folder, class_name)\n",
    "        all_images.extend(images)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "all_images = preprocess(all_images)\n",
    "\n",
    "# Making labels to intergers\n",
    "unique_labels = list(set(all_labels))\n",
    "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "all_labels = [label_to_int[label] for label in all_labels]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_images, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM\n",
    "svm = SVC(kernel='linear', decision_function_shape='ovr')  # 'ovr' stands for One-vs-Rest\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=unique_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Similar Signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "IGI_Neo-Babylonian       0.17      0.29      0.21        56\n",
      "   MU_Neo-Assyrian       0.26      0.35      0.30        31\n",
      "GIŠ_Neo-Babylonian       0.11      0.20      0.14        30\n",
      "   UD_Neo-Assyrian       0.11      0.10      0.11        29\n",
      " AŠ_Neo-Babylonian       0.35      0.46      0.40       103\n",
      " NU_Neo-Babylonian       0.23      0.25      0.24        77\n",
      "  GIŠ_Neo-Assyrian       0.17      0.19      0.18        37\n",
      "  BAD_Neo-Assyrian       0.34      0.55      0.42        42\n",
      "DIŠ_Neo-Babylonian       0.46      0.54      0.49       258\n",
      "BAD_Neo-Babylonian       0.37      0.38      0.37        56\n",
      "   NU_Neo-Assyrian       0.14      0.25      0.18        24\n",
      "   AN_Neo-Assyrian       0.17      0.16      0.17        70\n",
      " AN_Neo-Babylonian       0.43      0.37      0.40       249\n",
      " UD_Neo-Babylonian       0.29      0.27      0.28       139\n",
      "    I_Neo-Assyrian       0.27      0.17      0.21        24\n",
      "  IGI_Neo-Assyrian       0.29      0.19      0.23        53\n",
      "   NA_Neo-Assyrian       0.29      0.19      0.23        32\n",
      "  A_Neo-Babylonian       0.46      0.45      0.46       214\n",
      " MA_Neo-Babylonian       0.42      0.37      0.40       107\n",
      "    A_Neo-Assyrian       0.20      0.18      0.19        38\n",
      "   MA_Neo-Assyrian       0.32      0.27      0.29        49\n",
      "ŠU₂_Neo-Babylonian       0.30      0.26      0.28        78\n",
      " NA_Neo-Babylonian       0.36      0.26      0.30       121\n",
      "  ŠU₂_Neo-Assyrian       0.25      0.36      0.29        28\n",
      "  I_Neo-Babylonian       0.40      0.27      0.32        89\n",
      "   AŠ_Neo-Assyrian       0.28      0.27      0.28        41\n",
      "  DIŠ_Neo-Assyrian       0.41      0.44      0.43        61\n",
      " MU_Neo-Babylonian       0.26      0.17      0.21       104\n",
      "\n",
      "          accuracy                           0.34      2240\n",
      "         macro avg       0.29      0.29      0.29      2240\n",
      "      weighted avg       0.34      0.34      0.34      2240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading of the images and assigning a label to each image\n",
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = plt.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Resize the images and flatten\n",
    "def preprocess(images):\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        resized_img = cv2.resize(img, (128, 128))  \n",
    "        flattened_img = resized_img.flatten()\n",
    "        processed_images.append(flattened_img)\n",
    "    return processed_images\n",
    "\n",
    "root_folder = 'similar signs'\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "for class_name in os.listdir(root_folder):\n",
    "    class_folder = os.path.join(root_folder, class_name)\n",
    "    if os.path.isdir(class_folder):\n",
    "        images, labels = load_images_from_folder(class_folder, class_name)\n",
    "        all_images.extend(images)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "all_images = preprocess(all_images)\n",
    "\n",
    "# Making labels to intergers\n",
    "unique_labels = list(set(all_labels))\n",
    "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "all_labels = [label_to_int[label] for label in all_labels]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_images, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM\n",
    "svm = SVC(kernel='linear', decision_function_shape='ovr')  # 'ovr' stands for One-vs-Rest\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=unique_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

#%%
import sys
sys.path.append("../")
sys.path.append("../data_retrieval/data/")
#from data_retrieval.data import split_data
from torchvision import transforms
from torchvision.models import resnet50
from torchvision.datasets import ImageFolder
import json
import torch
import matplotlib.pyplot as plt
import numpy as np
#%%
MEAN, STD = 0.0052, 0.0018
data_transforms = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize(mean=MEAN, std=STD)
])
#%%
labasi_data = ImageFolder('../data_retrieval/labasi_data/data/',data_transforms)
#%%
model = resnet50()
#%%
model.load_state_dict(torch.load('../models/models_weights/resnet50.pth', map_location=torch.device('cpu')))
#%%
model.eval()
#%%
test_loader = torch.utils.data.DataLoader(labasi_data,
                                             batch_size=1, shuffle=True,
                                             num_workers=4)
#%%
idx_to_class = {v: k for k, v in labasi_data.class_to_idx.items()}
#%%
print(idx_to_class)
#%%
f = open("../data_retrieval/data/mapping")
mapping = json.load(f)
#%%
inv_normalize = transforms.Normalize(
    mean=[MEAN/0.229],
    std=[1/STD]
)

    
    
    
def saliency(img, model):
    #we don't need gradients w.r.t. weights for a trained model
    for param in model.parameters():
        param.requires_grad = False
    
    #set model in eval mode
    model.eval()
    #transoform input PIL image to torch.Tensor and normalize
    input = transform(img)
    input.unsqueeze_(0)

    #we want to calculate gradient of higest score w.r.t. input
    #so set requires_grad to True for input 
    input.requires_grad = True
    #forward pass to calculate predictions
    preds = model(input)
    score, indices = torch.max(preds, 1)
    #backward pass to get gradients of score predicted class w.r.t. input image
    score.backward()
    #get max along channel axis
    slc, _ = torch.max(torch.abs(input.grad[0]), dim=0)
    #normalize to [0..1]
    slc = (slc - slc.min())/(slc.max()-slc.min())

    #apply inverse transform on image
    with torch.no_grad():
        input_img = inv_normalize(input[0])
    #plot image and its saleincy map
    plt.figure(figsize=(10, 10))
    plt.subplot(1, 2, 1)
    plt.imshow(np.transpose(input_img.detach().numpy(), (1, 2, 0)))
    plt.xticks([])
    plt.yticks([])
    plt.subplot(1, 2, 2)
    plt.imshow(slc.numpy(), cmap=plt.cm.hot)
    plt.xticks([])
    plt.yticks([])
    plt.show()
    

correct_pred = {classname: 0 for classname in idx_to_class}
total_pred = {classname: 0 for classname in idx_to_class}
for param in model.parameters():
    param.requires_grad = False

for data in test_loader:
    images, labels = data
    images.requires_grad = True
    outputs = model(images)
    score, predictions = torch.max(outputs, 1)
    score.backward()
    slc, _ = torch.max(torch.abs(images.grad[0]), dim=0)
    #normalize to [0..1]
    slc = (slc - slc.min())/(slc.max()-slc.min())

    #apply inverse transform on image
    with torch.no_grad():
        input_img = inv_normalize(images[0])
    #plot image and its saleincy map
    plt.figure(figsize=(10, 10))
    plt.subplot(1, 2, 1)
    plt.imshow(np.transpose(input_img.detach().numpy(), (1, 2, 0)))
    plt.xticks([])
    plt.yticks([])
    plt.subplot(1, 2, 2)
    plt.imshow(slc.numpy(), cmap=plt.cm.hot)
    plt.xticks([])
    plt.yticks([])
    plt.show()
    for label, prediction in zip(labels, predictions):
        if idx_to_class[int(label)] + "_Neo-Babylonian" == mapping[str(int(prediction))]:
            correct_pred[int(label)] += 1
        total_pred[int(label)] += 1

#%%
for classname, correct_count in correct_pred.items():
    print(classname)
    accuracy = 100 * float(correct_count) / total_pred[classname]
    print(f'Accuracy for class: {idx_to_class[classname]:5s} is {accuracy:.1f} %')
#%%
print("Overall accuracy: ",sum(correct_pred.values()) / sum(total_pred.values()))
#%%
